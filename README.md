# ai_detector
AI vs Human Text and Audio Detection Model 

**Introduction**
This project develops a model to distinguish between AI-generated and human-made text, audio, and images, addressing the growing need for content authenticity. The model is trained on diverse datasets and deployed as a Streamlit app, allowing users to input text, upload audio, or submit images for instant predictions, ensuring content integrity.


Audio Detection

**Objective:**
To build a model that can distinguish between an AI-generated deepfake voice vs real human speech.

**Dataset:** 
The model is trained using a combination of datasets like the TIMIT-TTS dataset, which contains a variety of synthetic audio files and LibriSpeech which contains a multitude of real human speakers' audio.

**Model Training:**
The following models were trained and evaluated for this task:
- XGBoost:
  - Achieved highest precision, recall, F1 score, accuracy, ROC-AUC scorea and EER among all models.
  - Selected as the final model due to superior performance.
- LightGBM
- VGG16

**Tech Stack:**
- Librosa & IPython: Used for feature extraction from audio files (e.g., MFCC, zero-crossing rates, chroma features).
- Scikit-learn: Used for XGBoost.
- Streamlit: Developed a web interface where users can upload audio files for real-time prediction.

**Conclusion:**
The XGBoost model was chosen due to its superior overall performance in metrics scores. The project successfully demonstrated how ML models can detect synthetic audio, offering a valuable tool to counteract the potential misuse of AI in audio content creation.



Text Detection

**Objective:**
The goal of this project is to build a classification model that distinguishes between AI-generated text and human-written content. For example, the model can help detect whether a student or an LLM (Large Language Model), like ChatGPT, wrote an essay.    

**Dataset:** 
We used the LLM-Detect AI Generated Text Dataset to train the model and ensure accurate classification.

**Model Training:**
The following models were trained and evaluated for this task:

- Logistic Regression: Used to classify text based on TF-IDF features.
- Random Forest: Utilized ensemble learning on TF-IDF features for better generalization.
- Support Vector Machine (SVM): 
  - Achieved the highest F1 score among all models.
  - Selected as the final model for deployment due to superior performance.  
- BERT (Transformer Model): Fine-tuned on the dataset using the Transformers Library, but SVM outperformed it in terms of practical deployment.

**Tech Stack:**
- Scikit-learn: Used for training and evaluating the models.  
- Transformers Library: For experimentation with pre-trained models like BERT.  
- Streamlit: Built an interactive web app to allow users to input text and get predictions in real-time.



Image Detection

**Objective:**  
This project develops a model to differentiate between AI-generated and real images, ensuring content authenticity in the digital age.

**Dataset:**  
The model is trained on the CIFake dataset, which includes both real and AI-generated images, enabling accurate classification of authentic versus synthetic images.

**Model Training:**  
The following components were utilized for training:
- ResNet-18:
  - A pre-trained CNN, leveraging weights from ImageNet for transfer learning.
- Adam Optimizer:
  - Paired with the cross-entropy loss function for effective multi-class classification training.

**Tech Stack:**  
- Scikit-learn:
  - Used for model training, evaluation, and performance tracking.  
- Streamlit:
  - Developed an interactive web app that allows users to upload images and receive real-time predictions.

**Conclusion:**  
The Image Classifier, powered by ResNet-18 and fine-tuned on the CIFake dataset, effectively distinguishes between real and AI-generated images. It integrates into a larger AI system designed to ensure content authenticity, providing real-time predictions through a user-friendly web app.


**Conclusion:**
The SVM model was chosen for deployment because it provided the best F1 score and overall performance. This project showcases how ML models can effectively identify text generated by AI systems, ensuring academic and professional integrity.
