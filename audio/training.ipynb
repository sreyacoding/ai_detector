{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb452e49-91af-413b-90ef-3858748fee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to dataset\n",
    "real_df = pd.read_csv(r\"C:\\Users\\hiran\\OneDrive\\Desktop\\AI 1-0\\Datasets\\BIGGER DATASET\\FEATURES\\real_audio_features.csv\")\n",
    "fake_df = pd.read_csv(r\"C:\\Users\\hiran\\OneDrive\\Desktop\\AI 1-0\\Datasets\\BIGGER DATASET\\FEATURES\\fake_audio_features.csv\")\n",
    "\n",
    "# 1 for fake, 0 for real\n",
    "real_df['label'] = 0\n",
    "fake_df['label'] = 1\n",
    "\n",
    "# One dataframe for real and fake\n",
    "combined_df = pd.concat([real_df, fake_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e75f5a8-edd4-4c93-9725-d74fe05c650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized columns: []\n",
      "mel_spectrogram       float64\n",
      "spectrogram           float64\n",
      "mfccs                 float64\n",
      "delta_mfccs           float64\n",
      "delta2_mfccs          float64\n",
      "zero_crossing_rate    float64\n",
      "chroma_features       float64\n",
      "cqt                   float64\n",
      "log_spectrogram       float64\n",
      "label                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Summary statistics\n",
    "def summarize_array_features(df):\n",
    "    array_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                df[col] = df[col].apply(lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else x)\n",
    "                \n",
    "                if df[col].apply(lambda x: isinstance(x, np.ndarray)).all():\n",
    "                    array_cols.append(col)\n",
    "                    \n",
    "                    df[col + '_mean'] = df[col].apply(np.mean)\n",
    "                    df[col + '_std'] = df[col].apply(np.std)\n",
    "                    df[col + '_min'] = df[col].apply(np.min)\n",
    "                    df[col + '_max'] = df[col].apply(np.max)\n",
    "                    \n",
    "                    df.drop(columns=[col], inplace=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping column {col} due to error: {e}\")\n",
    "    \n",
    "    print(f\"Summarized columns: {array_cols}\")\n",
    "    return df\n",
    "\n",
    "# Summarization function\n",
    "combined_df_summarized = summarize_array_features(combined_df)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined_df_summarized.drop(columns=['file_name'], inplace=True, errors='ignore')\n",
    "\n",
    "print(combined_df_summarized.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04155f44-71bd-4c29-a8fc-ac2edaaa4807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set label distribution:\n",
      "label\n",
      "0    936\n",
      "1    883\n",
      "Name: count, dtype: int64\n",
      "Test set label distribution:\n",
      "label\n",
      "0    234\n",
      "1    221\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "real_csv_path = 'real_audio_features.csv'\n",
    "fake_csv_path = 'fake_audio_features.csv'\n",
    "\n",
    "real_df = pd.read_csv(real_csv_path)\n",
    "fake_df = pd.read_csv(fake_csv_path)\n",
    "\n",
    "combined_df = pd.concat([real_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Extract features and labels\n",
    "X = combined_df.drop(columns=['filename', 'label'])\n",
    "y = combined_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # To ensure balanced splits\n",
    ")\n",
    "\n",
    "print(f\"Training set label distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Test set label distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e468b-d738-454c-80b0-c2570b8e97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "X_train = X_train.drop(columns=['filename'], errors='ignore')  # Assuming filename was included\n",
    "X_test = X_test.drop(columns=['filename'], errors='ignore')    # Same for test data\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Optionally, save the model for later use\n",
    "xgb_model.save_model('xgb_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b24a1ec6-8dc1-469f-9b60-2deda9a3775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9987817612252001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Prediction probabilities\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "469b7b39-741a-457a-9be3-6f073cef3517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Error Rate (EER): 0.01282051282051282\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# FPR, TPR and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# FRR = 1 - TPR\n",
    "frr = 1 - tpr\n",
    "\n",
    "# Threshold where FAR = FRR\n",
    "eer_threshold = thresholds[np.nanargmin(np.absolute((fpr - frr)))]\n",
    "\n",
    "eer = fpr[np.nanargmin(np.absolute((fpr - frr)))]\n",
    "print(f\"Equal Error Rate (EER): {eer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
